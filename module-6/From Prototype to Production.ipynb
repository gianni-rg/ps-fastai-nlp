{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy as web service\n",
    "\n",
    "Once you've tested the model and are satisfied with the results, deploy the model as a web service hosted in ACI.\n",
    "\n",
    "To build the correct environment for ACI, provide the following:\n",
    "\n",
    "- A scoring script to show how to use the model\n",
    "- An environment file to show what packages need to be installed\n",
    "- A configuration file to build the ACI\n",
    "- The model you trained before\n",
    "\n",
    "In the previous module, we trained a machine learning model.\n",
    "\n",
    "Now, we're ready to deploy the model as a web service in cloud, leveraging Microsoft Azure Container Instances (ACI). A web service is an image, in this case a Docker image, that encapsulates the scoring logic and the model itself.\n",
    "\n",
    "### Deployment workflow\n",
    "\n",
    "The process of deploying a model is similar for all compute targets:\n",
    "\n",
    "1. Train a model.\n",
    "2. Register the model.\n",
    "3. Create an image configuration.\n",
    "4. Create the image.\n",
    "5. Deploy the image to a compute target.\n",
    "6. Test the deployment\n",
    "\n",
    "\n",
    "The following code is based on the official Microsoft Azure Machine Learning documentation tutorial, https://docs.microsoft.com/en-us/azure/machine-learning/service/tutorial-deploy-models-with-aml\n",
    "\n",
    "We need to setup our dev environment in Azure first, by following the steps listed in the official documentation [here](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-configure-environment#workspace) and [here](https://docs.microsoft.com/en-us/azure/machine-learning/service/quickstart-get-started)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml\n",
    "from azureml.core import Workspace, Run\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.image import ContainerImage\n",
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.webservice import AciWebservice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can choose to setup your workspace directly from the Azure Portal, or running the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_subscription_id = 'YOUR-SUBSCRIPTION-ID'\n",
    "azure_resource_group  = 'ps-fastai-rg'\n",
    "azure_mlworkspace_name  = 'ps-fastai'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Azure Machine Learning Workspace\n",
    "ws = Workspace.create(name=azure_mlworkspace_name,\n",
    "                      subscription_id=azure_subscription_id, \n",
    "                      resource_group=azure_resource_group,\n",
    "                      create_resource_group=True,\n",
    "                      location='westeurope' # Or other supported Azure region   \n",
    "                     )\n",
    "\n",
    "# Save the configuration file\n",
    "ws.write_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you created the Workspace from the Azure Portal, you can get a reference to it by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ws = Workspace(subscription_id = azure_subscription_id, resource_group = azure_resource_group, workspace_name = azure_mlworkspace_name)\n",
    "    ws.write_config()\n",
    "    print('Library configuration succeeded')\n",
    "except:\n",
    "    print('Workspace not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws.get_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to workspace\n",
    "Once you have the configuration file, Workspace can be loaded using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load workspace configuration from the config.json file in the current folder.\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.location, ws.resource_group, ws.location, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../datasets/20news/models/final_for_prod.pth'\n",
    "model_name = \"ps-fastai-nlp-classification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model.register(model_path = model_path,\n",
    "                       model_name = model_name,\n",
    "                       tags = {\"key\": \"0.1\"},\n",
    "                       description = \"Pluralsight Fast.AI NLP Classification Model\",\n",
    "                       workspace = ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model.list(ws, name=model_name)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create scoring script\n",
    "\n",
    "Create the scoring script, called `score.py`, used by the web service call to show how to use the model.\n",
    "\n",
    "You must include two required functions into the scoring script:\n",
    "\n",
    "The `init()` function, which typically loads the model into a global object. This function is run only once when the Docker container is started.\n",
    "\n",
    "The `run(input_data)` function uses the model to predict a value based on the input data. Inputs and outputs to the run typically use JSON for serialization and de-serialization, but other formats are supported.\n",
    "\n",
    "The following script is based on https://github.com/fastai/fastai/blob/master/courses/dl2/imdb_scripts/predict_with_classifier.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./score.py\n",
    "from fastai.text import *\n",
    "from azureml.core.model import Model\n",
    "from html.parser import HTMLParser\n",
    "\n",
    "class HTMLTextExtractor(html.parser.HTMLParser):\n",
    "    def __init__(self):\n",
    "        super(HTMLTextExtractor, self).__init__()\n",
    "        self.result = [ ]\n",
    "\n",
    "    def handle_data(self, d):\n",
    "        self.result.append(d)\n",
    "\n",
    "    def get_text(self):\n",
    "        return ''.join(self.result)\n",
    "    \n",
    "    def error(self, message):\n",
    "        return\n",
    "\n",
    "def html_to_text(html):\n",
    "    s = HTMLTextExtractor()    \n",
    "    try:\n",
    "        s.feed(html)\n",
    "        return s.get_text()\n",
    "    except:\n",
    "        return html\n",
    "\n",
    "def custom_tagstrip(x:str) -> str:\n",
    "    \"Remove all html tags in `x`.\"\n",
    "    return html_to_text(x)\n",
    "\n",
    "def load_model(classifier_filename):\n",
    "    \"\"\"Load the classifier and related metadata\"\"\"\n",
    "    \n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print('USING CUDA-GPU')\n",
    "    else:\n",
    "        print('USING CPU')\n",
    "    \n",
    "    state = torch.load(Path(classifier_filename).open('rb'), map_location=device)\n",
    "    \n",
    "    if set(state.keys()) == {'model', 'model_params', 'vocab', 'classes'}:\n",
    "        model_state = state['model']\n",
    "        model_params = state['model_params']\n",
    "        itos = state['vocab']\n",
    "        classes = state['classes']\n",
    "    else:\n",
    "        raise RuntimeError(\"Invalid model provided.\")\n",
    "        \n",
    "    # Turn it into a string to int mapping (which is what we need)\n",
    "    stoi = collections.defaultdict(lambda:0, {str(v):int(k) for k,v in enumerate(itos)})\n",
    "    \n",
    "    # Get model reference from parameters (even if they are not used at runtime)\n",
    "    model = get_rnn_classifier(bptt=model_params['bptt'],\n",
    "                               max_seq=model_params['max_len'],\n",
    "                               #model_params['n_class'],#removed in 1.0.41\n",
    "                               vocab_sz=model_params['vocab_size'], \n",
    "                               emb_sz=model_params['emb_sz'],\n",
    "                               n_hid=model_params['nh'],\n",
    "                               n_layers=model_params['nl'],\n",
    "                               pad_token=model_params['pad_token'],\n",
    "                               layers=model_params['layers'],\n",
    "                               drops=model_params['ps'],\n",
    "                               input_p=model_params['dps'][0],\n",
    "                               weight_p=model_params['dps'][1],\n",
    "                               embed_p=model_params['dps'][2],\n",
    "                               hidden_p=model_params['dps'][3],\n",
    "                               qrnn=model_params['qrnn'])\n",
    "\n",
    "    # Load the trained classifier\n",
    "    model.load_state_dict(model_state)\n",
    "    \n",
    "    # Put the classifier into evaluation mode\n",
    "    model.reset()\n",
    "    model.eval()\n",
    "\n",
    "    return stoi, classes, model\n",
    "\n",
    "def predict_text(stoi, model, lang, text):\n",
    "    \"\"\"Do the actual prediction on the text using the model and mapping files passed\"\"\"\n",
    "\n",
    "    # Predictions are done on arrays of input.\n",
    "    # We only have a single input, so turn it into a 1x1 array\n",
    "    texts = [text]\n",
    "\n",
    "    # Tokenize using the FastAI wrapper around spaCy\n",
    "    pre_rules = [custom_tagstrip] + defaults.text_pre_rules\n",
    "    tokens = Tokenizer(lang=lang, pre_rules=pre_rules, n_cpus=1).process_all(texts)\n",
    "\n",
    "    # Turn into integers for each word\n",
    "    encoded = np.array([[stoi[o] for o in p] for p in tokens], dtype=np.int64)\n",
    "    \n",
    "    # Turn this array into a tensor\n",
    "    data = torch.from_numpy(encoded)\n",
    "\n",
    "    # Do the predictions\n",
    "    predictions = model(data)\n",
    "    \n",
    "    # Get class probability from classifier predictions\n",
    "    res = F.softmax(predictions[0], -1).detach().cpu().numpy()\n",
    "    \n",
    "    return res[0]\n",
    "\n",
    "def init():\n",
    "    global stoi\n",
    "    global classes\n",
    "    global model\n",
    "    \n",
    "    # Retrieve the path to the model file using the model name\n",
    "    model_path = Model.get_model_path(model_name='ps-fastai-nlp-classification')\n",
    "    stoi, classes, model = load_model(model_path)\n",
    "\n",
    "def run(raw_data):\n",
    "    deser_obj = json.loads(raw_data)\n",
    "    \n",
    "    if not set(deser_obj.keys()) == {'lang', 'text' }:\n",
    "        return { \"error\": \"invalid data\" }\n",
    "    \n",
    "    lang = deser_obj['lang']\n",
    "    text = deser_obj['text']\n",
    "    \n",
    "    # Make prediction  \n",
    "    scores = predict_text(stoi, model, lang, text)\n",
    "    pred_class = np.argmax(scores)\n",
    "    \n",
    "    # You can return any data type as long as it is JSON-serializable\n",
    "    # We have to cast numpy data types (non-serializable) to standard types\n",
    "    # See: https://stackoverflow.com/questions/26646362/numpy-array-is-not-json-serializable\n",
    "    return { \"label\": classes[pred_class], \"label_index\": int(pred_class), \"label_score\": float(scores[pred_class]), \"all_scores\": scores.tolist() }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create environment file\n",
    "\n",
    "Next, create an environment file, called myenv.yml, that specifies all of the script's package dependencies. This file is used to ensure that all of those dependencies are installed in the Docker image. This model needs `pytorch`, `fastai` and `azureml-sdk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myenv = CondaDependencies()\n",
    "myenv.set_python_version(\"3.6.6\")\n",
    "myenv.add_pip_package(\"torch==1.0.0\")\n",
    "#myenv.add_pip_package(\"https://download.pytorch.org/whl/cu100/torch-1.0.0-cp36-cp36m-linux_x86_64.whl\")\n",
    "myenv.add_pip_package(\"torchvision==0.2.1\")\n",
    "myenv.add_pip_package(\"fastai==1.0.42\")\n",
    "\n",
    "with open(\"myenv.yml\",\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test conda environment locally (in Anaconda Prompt):\n",
    "\n",
    "`> conda env create -f nbs\\myenv.yml`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Create an image configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deployed models are packaged as an image. The image contains the dependencies needed to run the model.\n",
    "\n",
    "For Azure Container Instance or Azure Kubernetes Service the azureml.core.image.ContainerImage class is used to create an image configuration. The image configuration is then used to create a new Docker image.\n",
    "\n",
    "For details, see: https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.image.containerimage?view=azure-ml-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_config = ContainerImage.image_configuration(execution_script = \"score.py\",\n",
    "                                                  runtime = \"python\",\n",
    "                                                  conda_file = \"myenv.yml\",\n",
    "                                                  docker_file=\"Dockerfile\",\n",
    "                                                  enable_gpu=True,\n",
    "                                                  description = \"Image with Fast.AI NLP classification model with GPU\",\n",
    "                                                  tags = {\"data\": \"20newsgroup\", \"type\": \"classification\"}\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the image\n",
    "\n",
    "Once you have created the image configuration, you can use it to create an image. This image is stored in the container registry for your workspace.\n",
    "\n",
    "Once created, you can deploy the same image to multiple services. Images are versioned automatically when you register multiple images with the same name. For example, the first image registered as `myimage` is assigned an ID of `myimage:1`. The next time you register an image as `myimage`, the ID of the new image is `myimage:2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Create the image from the image configuration\n",
    "image = ContainerImage.create(name = \"myimage\", \n",
    "                              models = [model], #this is the model object\n",
    "                              image_config = image_config,\n",
    "                              workspace = ws\n",
    "                              )\n",
    "image.wait_for_creation(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of errors, you can get logs with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you already have the image object handy\n",
    "print(image.image_build_log_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you only know the name of the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you only know the name of the image (note there might be multiple images with the same name but different version number)\n",
    "print(ws.images['myimage'].image_build_log_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the image\n",
    "\n",
    "When you get to deployment, the process is slightly different depending on the compute target that you deploy to. Use the information in the following sections to learn how to deploy to:\n",
    "\n",
    "- Azure Container Instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy in ACI\n",
    "\n",
    "Estimated time to complete: about 7-8 minutes\n",
    "\n",
    "Configure the image and deploy. The following code goes through these steps:\n",
    "\n",
    "1. Build an image using:\n",
    "   - The scoring file (score.py)\n",
    "   - The environment file (myenv.yml)\n",
    "   - The model file\n",
    "2. Register that image under the workspace.\n",
    "3. Send the image to the ACI container.\n",
    "4. Start up a container in ACI using the image.\n",
    "5. Get the web service HTTP endpoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores = 1, \n",
    "                                               memory_gb = 1, \n",
    "                                               tags = {\"data\": \"20newsgroup\", \"type\": \"classification\"}, \n",
    "                                               description = 'Fast.AI NLP Classification GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = ws.images[\"myimage\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "service_name = 'aci-fastai-1'\n",
    "service = Webservice.deploy_from_image(deployment_config = aciconfig,\n",
    "                                            image = image,\n",
    "                                            name = service_name,\n",
    "                                            workspace = ws)\n",
    "service.wait_for_deployment(show_output = True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.get_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image.image_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the scoring web service's HTTP endpoint, which accepts REST client calls. This endpoint can be shared with anyone who wants to test the web service or integrate it into an application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.scoring_uri)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
